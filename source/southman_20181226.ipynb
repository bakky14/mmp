{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import category_encoders as ce\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러올 데이터의 타입과 컬럼을 정의한다.\n",
    "column_dtypes = {\n",
    "        'MachineIdentifier':                                    'object',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float16',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float16',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int8',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float32',\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float16',\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float16',\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float32',\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float32',\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float32',\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "\n",
    "use_columns = ['MachineIdentifier'\n",
    "    ,'ProductName'\n",
    "    ,'EngineVersion'\n",
    "    ,'AppVersion'\n",
    "    ,'AvSigVersion'\n",
    "    ,'IsBeta'\n",
    "    ,'RtpStateBitfield'\n",
    "    ,'IsSxsPassiveMode'\n",
    "    ,'DefaultBrowsersIdentifier'\n",
    "    ,'AVProductStatesIdentifier'\n",
    "    ,'AVProductsInstalled'\n",
    "    ,'AVProductsEnabled'\n",
    "    ,'HasTpm'\n",
    "    ,'CountryIdentifier'\n",
    "    ,'CityIdentifier'\n",
    "    ,'OrganizationIdentifier'\n",
    "    ,'GeoNameIdentifier'\n",
    "    ,'LocaleEnglishNameIdentifier'\n",
    "    ,'Platform'\n",
    "    ,'Processor'\n",
    "    ,'OsVer'\n",
    "    ,'OsBuild'\n",
    "    ,'OsSuite'\n",
    "    ,'OsPlatformSubRelease'\n",
    "    ,'OsBuildLab'\n",
    "    ,'SkuEdition'\n",
    "    ,'IsProtected'\n",
    "    ,'AutoSampleOptIn'\n",
    "    ,'PuaMode'\n",
    "    ,'SMode'\n",
    "    ,'IeVerIdentifier'\n",
    "    ,'SmartScreen'\n",
    "    ,'Firewall'\n",
    "    ,'UacLuaenable'\n",
    "    ,'Census_MDC2FormFactor'\n",
    "    ,'Census_DeviceFamily'\n",
    "    ,'Census_OEMNameIdentifier'\n",
    "    ,'Census_OEMModelIdentifier'\n",
    "    ,'Census_ProcessorCoreCount'\n",
    "    ,'Census_ProcessorManufacturerIdentifier'\n",
    "    ,'Census_ProcessorModelIdentifier'\n",
    "    ,'Census_ProcessorClass'\n",
    "    ,'Census_PrimaryDiskTotalCapacity'\n",
    "    ,'Census_PrimaryDiskTypeName'\n",
    "    ,'Census_SystemVolumeTotalCapacity'\n",
    "    ,'Census_HasOpticalDiskDrive'\n",
    "    ,'Census_TotalPhysicalRAM'\n",
    "    ,'Census_ChassisTypeName'\n",
    "    ,'Census_InternalPrimaryDiagonalDisplaySizeInInches'\n",
    "    ,'Census_InternalPrimaryDisplayResolutionHorizontal'\n",
    "    ,'Census_PowerPlatformRoleName'\n",
    "    ,'Census_InternalBatteryType'\n",
    "    ,'Census_InternalBatteryNumberOfCharges'\n",
    "    ,'Census_OSVersion'\n",
    "    ,'Census_OSArchitecture'\n",
    "    ,'Census_OSBranch'\n",
    "    ,'Census_OSBuildRevision'\n",
    "    ,'Census_OSEdition'\n",
    "    ,'Census_OSSkuName'\n",
    "    ,'Census_OSInstallTypeName'\n",
    "    ,'Census_OSInstallLanguageIdentifier'\n",
    "    ,'Census_OSWUAutoUpdateOptionsName'\n",
    "    ,'Census_IsPortableOperatingSystem'\n",
    "    ,'Census_GenuineStateName'\n",
    "    ,'Census_ActivationChannel'\n",
    "    ,'Census_IsFlightingInternal'\n",
    "    ,'Census_IsFlightsDisabled'\n",
    "    ,'Census_FlightRing'\n",
    "    ,'Census_ThresholdOptIn'\n",
    "    ,'Census_FirmwareManufacturerIdentifier'\n",
    "    ,'Census_FirmwareVersionIdentifier'\n",
    "    ,'Census_IsSecureBootEnabled'\n",
    "    ,'Census_IsWIMBootEnabled'\n",
    "    ,'Census_IsVirtualDevice'\n",
    "    ,'Census_IsTouchEnabled'\n",
    "    ,'Census_IsPenCapable'\n",
    "    ,'Census_IsAlwaysOnAlwaysConnectedCapable'\n",
    "    ,'Wdft_IsGamer'\n",
    "    ,'Wdft_RegionIdentifier'\n",
    "    ,'HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 불러온다.\n",
    "zf = zipfile.ZipFile('../input/all.zip', 'r')\n",
    "tr_train = pd.read_csv(zf.open('train.csv'), dtype=column_dtypes, usecols= use_columns)\n",
    "X_test = pd.read_csv(zf.open('test.csv'), dtype=column_dtypes, usecols= use_columns[:-1])\n",
    "del zf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 xy를 분리한다.\n",
    "y_train = tr_train.HasDetections\n",
    "X_train = tr_train.drop(['HasDetections'], axis=1)\n",
    "del tr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoder를 실행한다.\n",
    "category_columns = list(X_train.select_dtypes(include=['category']).columns)\n",
    "enc = ce.TargetEncoder(cols=category_columns).fit(X_train, y_train)\n",
    "X_train = enc.transform(X_train)\n",
    "X_test = enc.transform(X_test)\n",
    "\n",
    "for column in category_columns:\n",
    "    X_train[column] = X_train[column].astype('float16')\n",
    "    X_test[column] = X_test[column].astype('float16')\n",
    "\n",
    "X_train.to_pickle(\"../result/X_train_target_encoded.pkl\")\n",
    "X_test.to_pickle(\"../result/X_test_target_encoded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_pickle(\"../result/X_train_target_encoded.pkl\")\n",
    "# X_test = pd.read_pickle(\"../result/X_test_target_encoded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 평균값으로 채운다.\n",
    "def fill_nan(df, column, mean):\n",
    "    dtype = df[column].dtype\n",
    "    if dtype == 'float16':\n",
    "        df[column] = df[column].astype('float32')\n",
    "    df[column].fillna(mean, inplace=True)\n",
    "    if dtype == 'float16':\n",
    "        df[column] = df[column].astype('float16')\n",
    "\n",
    "for column in list(X_train.columns[X_train.isna().any()]):\n",
    "    mean = X_train[column].mean()\n",
    "    fill_nan(X_train, column, mean)\n",
    "    fill_nan(X_test, column, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 저장 및 제거 \n",
    "ID_test = X_test.MachineIdentifier\n",
    "X_train.drop(['MachineIdentifier'], axis=1, inplace=True)\n",
    "X_test.drop(['MachineIdentifier'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'num_leaves': 60,\n",
    "         'min_data_in_leaf': 60, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.1,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002E11AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\s...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002E11AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\s...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(808, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(808, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (808, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=808, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 26, 8, 26, 25, 483888, tzinfo=tzutc()), 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'session': '1b53fc4358ec4b12874bd800e728ea34', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1b53fc4358ec4b12874bd800e728ea34']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 26, 8, 26, 25, 483888, tzinfo=tzutc()), 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'session': '1b53fc4358ec4b12874bd800e728ea34', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1b53fc4358ec4b12874bd800e728ea34'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 26, 8, 26, 25, 483888, tzinfo=tzutc()), 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'session': '1b53fc4358ec4b12874bd800e728ea34', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-54-054461f0af81>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at d649aa90, execution_c...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000000CA23E150, file \"<ipython-input-54-054461f0af81>\", line 26>\n        result = <ExecutionResult object at d649aa90, execution_c...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000000CA23E150, file \"<ipython-input-54-054461f0af81>\", line 26>, result=<ExecutionResult object at d649aa90, execution_c...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000000CA23E150, file \"<ipython-input-54-054461f0af81>\", line 26>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'ID_test': 0          0000010489e3af074adeac69c53e555e\n1   ...MachineIdentifier, Length: 7853253, dtype: object, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"# 불러올 데이터의 타입과 컬럼을 정의한다.\\ncolumn_dtypes = {\\n     ...   ,'Wdft_RegionIdentifier'\\n    ,'HasDetections']\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 학습 데이터의 xy를 분리한다.\\ny_train = tr_train.HasDetect...rain.drop(['HasDetections'], axis=1)\\ndel tr_train\", '# Target Encoder를 실행한다.\\ncategory_columns = list(....to_pickle(\"../result/X_test_target_encoded.pkl\")', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...llna(X_train.mean(), inplace=True)\\nX_train.isna()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()..._train.mean(), inplace=True)\\nX_train.isna().any()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...), inplace=True)\\ndf.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...place=True)\\nX_train.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...=True)\\nX_train.columns[X_train.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...ce=True)\\nX_test.columns[X_test.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    X_train[column].mean()\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...()]):\\n    print(X_train[column].mean())\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    print(X_train[column])\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', 'X_train.RtpStateBitfield.mean()', 'X_train.RtpStateBitfield.mean(skipna=False)', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {7:          MachineIdentifier  ProductName  EngineV...             False  \n\n[8921483 rows x 79 columns], 8: MachineIdentifier                               ...                     True\nLength: 79, dtype: bool, 10: Index(['RtpStateBitfield', 'DefaultBrowsersIdent..., 'Wdft_RegionIdentifier'],\n      dtype='object'), 11: 35, 12: 35, 18: nan, 19: nan, 20: nan, 21: 0          7.0\n1          7.0\n2          7.0\n3  ...RtpStateBitfield, Length: 8921483, dtype: float16, 22: nan, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'VotingClassifier': <class 'sklearn.ensemble.voting_classifier.VotingClassifier'>, 'XGBClassifier': <class 'xgboost.sklearn.XGBClassifier'>, 'X_test':          ProductName  EngineVersion  AppVersion ...              10.0  \n\n[7853253 rows x 78 columns], ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'ID_test': 0          0000010489e3af074adeac69c53e555e\n1   ...MachineIdentifier, Length: 7853253, dtype: object, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"# 불러올 데이터의 타입과 컬럼을 정의한다.\\ncolumn_dtypes = {\\n     ...   ,'Wdft_RegionIdentifier'\\n    ,'HasDetections']\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 학습 데이터의 xy를 분리한다.\\ny_train = tr_train.HasDetect...rain.drop(['HasDetections'], axis=1)\\ndel tr_train\", '# Target Encoder를 실행한다.\\ncategory_columns = list(....to_pickle(\"../result/X_test_target_encoded.pkl\")', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...llna(X_train.mean(), inplace=True)\\nX_train.isna()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()..._train.mean(), inplace=True)\\nX_train.isna().any()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...), inplace=True)\\ndf.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...place=True)\\nX_train.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...=True)\\nX_train.columns[X_train.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...ce=True)\\nX_test.columns[X_test.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    X_train[column].mean()\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...()]):\\n    print(X_train[column].mean())\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    print(X_train[column])\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', 'X_train.RtpStateBitfield.mean()', 'X_train.RtpStateBitfield.mean(skipna=False)', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {7:          MachineIdentifier  ProductName  EngineV...             False  \n\n[8921483 rows x 79 columns], 8: MachineIdentifier                               ...                     True\nLength: 79, dtype: bool, 10: Index(['RtpStateBitfield', 'DefaultBrowsersIdent..., 'Wdft_RegionIdentifier'],\n      dtype='object'), 11: 35, 12: 35, 18: nan, 19: nan, 20: nan, 21: 0          7.0\n1          7.0\n2          7.0\n3  ...RtpStateBitfield, Length: 8921483, dtype: float16, 22: nan, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'VotingClassifier': <class 'sklearn.ensemble.voting_classifier.VotingClassifier'>, 'XGBClassifier': <class 'xgboost.sklearn.XGBClassifier'>, 'X_test':          ProductName  EngineVersion  AppVersion ...              10.0  \n\n[7853253 rows x 78 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\southman\\Documents\\GitHub\\mmp\\source\\<ipython-input-54-054461f0af81> in <module>()\n     21 #    \"rf__n_estimators\":[45], \"rf__max_depth\":[20], \"rf__min_samples_leaf\":[3],\n     22 #    'mlp__solver':['adam'], 'mlp__max_iter':[1000], 'mlp__early_stopping':[True], \n     23 #    'mlp__hidden_layer_sizes':[(128,64,32)],'mlp__activation':['logistic'],\n     24 }\n     25 clf = GridSearchCV(clf_eb, parameters, n_jobs=-1, cv=5)\n---> 26 clf.fit(X_train, y_train)\n     27 #print(clf.best_params_)\n     28 score = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n     29 print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=         ProductName  EngineVersion  AppVersion ...              11.0  \n\n[8921483 rows x 78 columns], y=0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =          ProductName  EngineVersion  AppVersion ...              11.0  \n\n[8921483 rows x 78 columns]\n        y = 0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Wed Dec 26 17:29:25 2018\nPID: 6116              Python 3.6.5: C:\\Users\\southman\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = <class 'list'> instance\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = <class 'tuple'> instance\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=<class 'pandas.core.frame.DataFrame'> instance, y=0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8, scorer={'score': <function _passthrough_scorer>}, train=memmap([1783781, 1783782, 1783784, ..., 8921480, 8921481, 8921482]), test=memmap([      0,       1,       2, ..., 1784812, 1784813, 1784814]), verbose=0, parameters={'xgb__colsample_bytree': 0.84, 'xgb__gamma': 0.2, 'xgb__learning_rate': 0.2, 'xgb__max_depth': 4, 'xgb__min_child_weight': 4, 'xgb__reg_alpha': 0.01, 'xgb__subsample': 0.9}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method VotingClassifier.fit of VotingClas...orm=None, n_jobs=1, voting='soft', weights=None)>\n        X_train =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y_train = 1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in fit(self=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8, sample_weight=None)\n    184         transformed_y = self.le_.transform(y)\n    185 \n    186         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n    187                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n    188                                                  sample_weight=sample_weight)\n--> 189                 for clf in clfs if clf is not None)\n        clfs = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),)\n    190 \n    191         return self\n    192 \n    193     @property\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object VotingClassifier.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_fit_estimator>, (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64)), {'sample_weight': None})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_fit_estimator>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64))\n        kwargs = {'sample_weight': None}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in _parallel_fit_estimator(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None)\n     26 def _parallel_fit_estimator(estimator, X, y, sample_weight=None):\n     27     \"\"\"Private function used to fit an estimator within a job.\"\"\"\n     28     if sample_weight is not None:\n     29         estimator.fit(X, y, sample_weight=sample_weight)\n     30     else:\n---> 31         estimator.fit(X, y)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...1, seed=None, silent=True,\n       subsample=0.9)>\n        X =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y = array([1, 1, 1, ..., 1, 1, 0], dtype=int64)\n     32     return estimator\n     33 \n     34 \n     35 class VotingClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n    688         if sample_weight is not None:\n    689             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    690                                     missing=self.missing, nthread=self.n_jobs)\n    691         else:\n    692             train_dmatrix = DMatrix(X, label=training_labels,\n--> 693                                     missing=self.missing, nthread=self.n_jobs)\n        self.missing = nan\n        self.n_jobs = 1\n    694 \n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], label=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=None, feature_types=None, nthread=1)\n    358                 self._feature_types = feature_types\n    359             return\n    360 \n    361         data, feature_names, feature_types = _maybe_pandas_data(data,\n    362                                                                 feature_names,\n--> 363                                                                 feature_types)\n        feature_types = None\n    364 \n    365         data, feature_names, feature_types = _maybe_dt_data(data,\n    366                                                             feature_names,\n    367                                                             feature_types)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _maybe_pandas_data(data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], feature_names=['ProductName', 'EngineVersion', 'AppVersion', 'AvSigVersion', 'IsBeta', 'RtpStateBitfield', 'IsSxsPassiveMode', 'DefaultBrowsersIdentifier', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled', 'HasTpm', 'CountryIdentifier', 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'Platform', 'Processor', 'OsVer', ...], feature_types=['float', 'float', 'float', 'float', 'int', 'float', 'int', 'float', 'float', 'float', 'float', 'int', 'int', 'float', 'float', 'float', 'int', 'float', 'float', 'float', ...])\n    237             feature_names = data.columns.format()\n    238 \n    239     if feature_types is None:\n    240         feature_types = [PANDAS_DTYPE_MAPPER[dtype.name] for dtype in data_dtypes]\n    241 \n--> 242     data = data.values.astype('float')\n        data =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        data.values.astype = undefined\n    243 \n    244     return data, feature_names, feature_types\n    245 \n    246 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in values(self=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns])\n   4624         --------\n   4625         pandas.DataFrame.index : Retrievie the index labels\n   4626         pandas.DataFrame.columns : Retrieving the column names\n   4627         \"\"\"\n   4628         self._consolidate_inplace()\n-> 4629         return self._data.as_array(transpose=self._AXIS_REVERSED)\n        self._data.as_array = <bound method BlockManager.as_array of BlockMana...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n        self._AXIS_REVERSED = True\n   4630 \n   4631     @property\n   4632     def _values(self):\n   4633         \"\"\"internal implementation\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in as_array(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32, transpose=True, items=None)\n   3944             mgr = self\n   3945 \n   3946         if self._is_single_block or not self.is_mixed_type:\n   3947             arr = mgr.blocks[0].get_values()\n   3948         else:\n-> 3949             arr = mgr._interleave()\n        arr = undefined\n        mgr._interleave = <bound method BlockManager._interleave of BlockM...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n   3950 \n   3951         return arr.transpose() if transpose else arr\n   3952 \n   3953     def _interleave(self):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _interleave(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32)\n   3955         Return ndarray from blocks with specified item order\n   3956         Items must be contained in the blocks\n   3957         \"\"\"\n   3958         dtype = _interleaved_dtype(self.blocks)\n   3959 \n-> 3960         result = np.empty(self.shape, dtype=dtype)\n        result = undefined\n        self.shape = (78, 7137185)\n        dtype = dtype('float64')\n   3961 \n   3962         if result.shape[0] == 0:\n   3963             # Workaround for numpy 1.7 bug:\n   3964             #\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\", line 189, in fit\n    for clf in clfs if clf is not None)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\", line 31, in _parallel_fit_estimator\n    estimator.fit(X, y)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 693, in fit\n    missing=self.missing, nthread=self.n_jobs)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 363, in __init__\n    feature_types)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 242, in _maybe_pandas_data\n    data = data.values.astype('float')\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 4629, in values\n    return self._data.as_array(transpose=self._AXIS_REVERSED)\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\", line 3949, in as_array\n    arr = mgr._interleave()\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\", line 3960, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Wed Dec 26 17:29:25 2018\nPID: 6116              Python 3.6.5: C:\\Users\\southman\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = <class 'list'> instance\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = <class 'tuple'> instance\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=<class 'pandas.core.frame.DataFrame'> instance, y=0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8, scorer={'score': <function _passthrough_scorer>}, train=memmap([1783781, 1783782, 1783784, ..., 8921480, 8921481, 8921482]), test=memmap([      0,       1,       2, ..., 1784812, 1784813, 1784814]), verbose=0, parameters={'xgb__colsample_bytree': 0.84, 'xgb__gamma': 0.2, 'xgb__learning_rate': 0.2, 'xgb__max_depth': 4, 'xgb__min_child_weight': 4, 'xgb__reg_alpha': 0.01, 'xgb__subsample': 0.9}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method VotingClassifier.fit of VotingClas...orm=None, n_jobs=1, voting='soft', weights=None)>\n        X_train =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y_train = 1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in fit(self=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8, sample_weight=None)\n    184         transformed_y = self.le_.transform(y)\n    185 \n    186         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n    187                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n    188                                                  sample_weight=sample_weight)\n--> 189                 for clf in clfs if clf is not None)\n        clfs = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),)\n    190 \n    191         return self\n    192 \n    193     @property\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object VotingClassifier.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_fit_estimator>, (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64)), {'sample_weight': None})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_fit_estimator>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64))\n        kwargs = {'sample_weight': None}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in _parallel_fit_estimator(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None)\n     26 def _parallel_fit_estimator(estimator, X, y, sample_weight=None):\n     27     \"\"\"Private function used to fit an estimator within a job.\"\"\"\n     28     if sample_weight is not None:\n     29         estimator.fit(X, y, sample_weight=sample_weight)\n     30     else:\n---> 31         estimator.fit(X, y)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...1, seed=None, silent=True,\n       subsample=0.9)>\n        X =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y = array([1, 1, 1, ..., 1, 1, 0], dtype=int64)\n     32     return estimator\n     33 \n     34 \n     35 class VotingClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n    688         if sample_weight is not None:\n    689             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    690                                     missing=self.missing, nthread=self.n_jobs)\n    691         else:\n    692             train_dmatrix = DMatrix(X, label=training_labels,\n--> 693                                     missing=self.missing, nthread=self.n_jobs)\n        self.missing = nan\n        self.n_jobs = 1\n    694 \n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], label=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=None, feature_types=None, nthread=1)\n    358                 self._feature_types = feature_types\n    359             return\n    360 \n    361         data, feature_names, feature_types = _maybe_pandas_data(data,\n    362                                                                 feature_names,\n--> 363                                                                 feature_types)\n        feature_types = None\n    364 \n    365         data, feature_names, feature_types = _maybe_dt_data(data,\n    366                                                             feature_names,\n    367                                                             feature_types)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _maybe_pandas_data(data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], feature_names=['ProductName', 'EngineVersion', 'AppVersion', 'AvSigVersion', 'IsBeta', 'RtpStateBitfield', 'IsSxsPassiveMode', 'DefaultBrowsersIdentifier', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled', 'HasTpm', 'CountryIdentifier', 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'Platform', 'Processor', 'OsVer', ...], feature_types=['float', 'float', 'float', 'float', 'int', 'float', 'int', 'float', 'float', 'float', 'float', 'int', 'int', 'float', 'float', 'float', 'int', 'float', 'float', 'float', ...])\n    237             feature_names = data.columns.format()\n    238 \n    239     if feature_types is None:\n    240         feature_types = [PANDAS_DTYPE_MAPPER[dtype.name] for dtype in data_dtypes]\n    241 \n--> 242     data = data.values.astype('float')\n        data =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        data.values.astype = undefined\n    243 \n    244     return data, feature_names, feature_types\n    245 \n    246 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in values(self=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns])\n   4624         --------\n   4625         pandas.DataFrame.index : Retrievie the index labels\n   4626         pandas.DataFrame.columns : Retrieving the column names\n   4627         \"\"\"\n   4628         self._consolidate_inplace()\n-> 4629         return self._data.as_array(transpose=self._AXIS_REVERSED)\n        self._data.as_array = <bound method BlockManager.as_array of BlockMana...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n        self._AXIS_REVERSED = True\n   4630 \n   4631     @property\n   4632     def _values(self):\n   4633         \"\"\"internal implementation\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in as_array(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32, transpose=True, items=None)\n   3944             mgr = self\n   3945 \n   3946         if self._is_single_block or not self.is_mixed_type:\n   3947             arr = mgr.blocks[0].get_values()\n   3948         else:\n-> 3949             arr = mgr._interleave()\n        arr = undefined\n        mgr._interleave = <bound method BlockManager._interleave of BlockM...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n   3950 \n   3951         return arr.transpose() if transpose else arr\n   3952 \n   3953     def _interleave(self):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _interleave(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32)\n   3955         Return ndarray from blocks with specified item order\n   3956         Items must be contained in the blocks\n   3957         \"\"\"\n   3958         dtype = _interleaved_dtype(self.blocks)\n   3959 \n-> 3960         result = np.empty(self.shape, dtype=dtype)\n        result = undefined\n        self.shape = (78, 7137185)\n        dtype = dtype('float64')\n   3961 \n   3962         if result.shape[0] == 0:\n   3963             # Workaround for numpy 1.7 bug:\n   3964             #\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Wed Dec 26 17:29:25 2018\nPID: 6116              Python 3.6.5: C:\\Users\\southman\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = <class 'list'> instance\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = <class 'tuple'> instance\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=<class 'pandas.core.frame.DataFrame'> instance, y=0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8, scorer={'score': <function _passthrough_scorer>}, train=memmap([1783781, 1783782, 1783784, ..., 8921480, 8921481, 8921482]), test=memmap([      0,       1,       2, ..., 1784812, 1784813, 1784814]), verbose=0, parameters={'xgb__colsample_bytree': 0.84, 'xgb__gamma': 0.2, 'xgb__learning_rate': 0.2, 'xgb__max_depth': 4, 'xgb__min_child_weight': 4, 'xgb__reg_alpha': 0.01, 'xgb__subsample': 0.9}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method VotingClassifier.fit of VotingClas...orm=None, n_jobs=1, voting='soft', weights=None)>\n        X_train =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y_train = 1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in fit(self=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8, sample_weight=None)\n    184         transformed_y = self.le_.transform(y)\n    185 \n    186         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n    187                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n    188                                                  sample_weight=sample_weight)\n--> 189                 for clf in clfs if clf is not None)\n        clfs = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),)\n    190 \n    191         return self\n    192 \n    193     @property\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object VotingClassifier.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_fit_estimator>, (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64)), {'sample_weight': None})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_fit_estimator>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64))\n        kwargs = {'sample_weight': None}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in _parallel_fit_estimator(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None)\n     26 def _parallel_fit_estimator(estimator, X, y, sample_weight=None):\n     27     \"\"\"Private function used to fit an estimator within a job.\"\"\"\n     28     if sample_weight is not None:\n     29         estimator.fit(X, y, sample_weight=sample_weight)\n     30     else:\n---> 31         estimator.fit(X, y)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...1, seed=None, silent=True,\n       subsample=0.9)>\n        X =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y = array([1, 1, 1, ..., 1, 1, 0], dtype=int64)\n     32     return estimator\n     33 \n     34 \n     35 class VotingClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n    688         if sample_weight is not None:\n    689             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    690                                     missing=self.missing, nthread=self.n_jobs)\n    691         else:\n    692             train_dmatrix = DMatrix(X, label=training_labels,\n--> 693                                     missing=self.missing, nthread=self.n_jobs)\n        self.missing = nan\n        self.n_jobs = 1\n    694 \n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], label=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=None, feature_types=None, nthread=1)\n    358                 self._feature_types = feature_types\n    359             return\n    360 \n    361         data, feature_names, feature_types = _maybe_pandas_data(data,\n    362                                                                 feature_names,\n--> 363                                                                 feature_types)\n        feature_types = None\n    364 \n    365         data, feature_names, feature_types = _maybe_dt_data(data,\n    366                                                             feature_names,\n    367                                                             feature_types)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _maybe_pandas_data(data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], feature_names=['ProductName', 'EngineVersion', 'AppVersion', 'AvSigVersion', 'IsBeta', 'RtpStateBitfield', 'IsSxsPassiveMode', 'DefaultBrowsersIdentifier', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled', 'HasTpm', 'CountryIdentifier', 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'Platform', 'Processor', 'OsVer', ...], feature_types=['float', 'float', 'float', 'float', 'int', 'float', 'int', 'float', 'float', 'float', 'float', 'int', 'int', 'float', 'float', 'float', 'int', 'float', 'float', 'float', ...])\n    237             feature_names = data.columns.format()\n    238 \n    239     if feature_types is None:\n    240         feature_types = [PANDAS_DTYPE_MAPPER[dtype.name] for dtype in data_dtypes]\n    241 \n--> 242     data = data.values.astype('float')\n        data =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        data.values.astype = undefined\n    243 \n    244     return data, feature_names, feature_types\n    245 \n    246 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in values(self=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns])\n   4624         --------\n   4625         pandas.DataFrame.index : Retrievie the index labels\n   4626         pandas.DataFrame.columns : Retrieving the column names\n   4627         \"\"\"\n   4628         self._consolidate_inplace()\n-> 4629         return self._data.as_array(transpose=self._AXIS_REVERSED)\n        self._data.as_array = <bound method BlockManager.as_array of BlockMana...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n        self._AXIS_REVERSED = True\n   4630 \n   4631     @property\n   4632     def _values(self):\n   4633         \"\"\"internal implementation\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in as_array(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32, transpose=True, items=None)\n   3944             mgr = self\n   3945 \n   3946         if self._is_single_block or not self.is_mixed_type:\n   3947             arr = mgr.blocks[0].get_values()\n   3948         else:\n-> 3949             arr = mgr._interleave()\n        arr = undefined\n        mgr._interleave = <bound method BlockManager._interleave of BlockM...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n   3950 \n   3951         return arr.transpose() if transpose else arr\n   3952 \n   3953     def _interleave(self):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _interleave(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32)\n   3955         Return ndarray from blocks with specified item order\n   3956         Items must be contained in the blocks\n   3957         \"\"\"\n   3958         dtype = _interleaved_dtype(self.blocks)\n   3959 \n-> 3960         result = np.empty(self.shape, dtype=dtype)\n        result = undefined\n        self.shape = (78, 7137185)\n        dtype = dtype('float64')\n   3961 \n   3962         if result.shape[0] == 0:\n   3963             # Workaround for numpy 1.7 bug:\n   3964             #\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-054461f0af81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     25\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_eb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;31m#print(clf.best_params_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002E11AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\s...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002E11AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\s...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(808, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(808, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (808, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=808, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 26, 8, 26, 25, 483888, tzinfo=tzutc()), 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'session': '1b53fc4358ec4b12874bd800e728ea34', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1b53fc4358ec4b12874bd800e728ea34']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 26, 8, 26, 25, 483888, tzinfo=tzutc()), 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'session': '1b53fc4358ec4b12874bd800e728ea34', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1b53fc4358ec4b12874bd800e728ea34'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 26, 8, 26, 25, 483888, tzinfo=tzutc()), 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'session': '1b53fc4358ec4b12874bd800e728ea34', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'f66e83e344934610baf7d8ca28e308f3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import cross_val_sc...%0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-54-054461f0af81>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at d649aa90, execution_c...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000000CA23E150, file \"<ipython-input-54-054461f0af81>\", line 26>\n        result = <ExecutionResult object at d649aa90, execution_c...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000000CA23E150, file \"<ipython-input-54-054461f0af81>\", line 26>, result=<ExecutionResult object at d649aa90, execution_c...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000000CA23E150, file \"<ipython-input-54-054461f0af81>\", line 26>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'ID_test': 0          0000010489e3af074adeac69c53e555e\n1   ...MachineIdentifier, Length: 7853253, dtype: object, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"# 불러올 데이터의 타입과 컬럼을 정의한다.\\ncolumn_dtypes = {\\n     ...   ,'Wdft_RegionIdentifier'\\n    ,'HasDetections']\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 학습 데이터의 xy를 분리한다.\\ny_train = tr_train.HasDetect...rain.drop(['HasDetections'], axis=1)\\ndel tr_train\", '# Target Encoder를 실행한다.\\ncategory_columns = list(....to_pickle(\"../result/X_test_target_encoded.pkl\")', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...llna(X_train.mean(), inplace=True)\\nX_train.isna()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()..._train.mean(), inplace=True)\\nX_train.isna().any()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...), inplace=True)\\ndf.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...place=True)\\nX_train.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...=True)\\nX_train.columns[X_train.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...ce=True)\\nX_test.columns[X_test.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    X_train[column].mean()\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...()]):\\n    print(X_train[column].mean())\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    print(X_train[column])\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', 'X_train.RtpStateBitfield.mean()', 'X_train.RtpStateBitfield.mean(skipna=False)', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {7:          MachineIdentifier  ProductName  EngineV...             False  \n\n[8921483 rows x 79 columns], 8: MachineIdentifier                               ...                     True\nLength: 79, dtype: bool, 10: Index(['RtpStateBitfield', 'DefaultBrowsersIdent..., 'Wdft_RegionIdentifier'],\n      dtype='object'), 11: 35, 12: 35, 18: nan, 19: nan, 20: nan, 21: 0          7.0\n1          7.0\n2          7.0\n3  ...RtpStateBitfield, Length: 8921483, dtype: float16, 22: nan, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'VotingClassifier': <class 'sklearn.ensemble.voting_classifier.VotingClassifier'>, 'XGBClassifier': <class 'xgboost.sklearn.XGBClassifier'>, 'X_test':          ProductName  EngineVersion  AppVersion ...              10.0  \n\n[7853253 rows x 78 columns], ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'ID_test': 0          0000010489e3af074adeac69c53e555e\n1   ...MachineIdentifier, Length: 7853253, dtype: object, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"# 불러올 데이터의 타입과 컬럼을 정의한다.\\ncolumn_dtypes = {\\n     ...   ,'Wdft_RegionIdentifier'\\n    ,'HasDetections']\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 데이터를 불러온다.\\nzf = zipfile.ZipFile('../input/all....=column_dtypes, usecols= use_columns[:-1])\\ndel zf\", \"# 학습 데이터의 xy를 분리한다.\\ny_train = tr_train.HasDetect...rain.drop(['HasDetections'], axis=1)\\ndel tr_train\", '# Target Encoder를 실행한다.\\ncategory_columns = list(....to_pickle(\"../result/X_test_target_encoded.pkl\")', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...llna(X_train.mean(), inplace=True)\\nX_train.isna()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()..._train.mean(), inplace=True)\\nX_train.isna().any()', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...), inplace=True)\\ndf.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...place=True)\\nX_train.columns[X_train.isna().any()]', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...=True)\\nX_train.columns[X_train.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...ce=True)\\nX_test.columns[X_test.isna().any()].size', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    X_train[column].mean()\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...()]):\\n    print(X_train[column].mean())\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...a().any()]):\\n    print(X_train[column])\\n    break', '# 결측치를 평균값으로 채운다.\\n#X_train.fillna(X_train.mean()...train.isna().any()]):\\n    print(column)\\n    break', 'X_train.RtpStateBitfield.mean()', 'X_train.RtpStateBitfield.mean(skipna=False)', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {7:          MachineIdentifier  ProductName  EngineV...             False  \n\n[8921483 rows x 79 columns], 8: MachineIdentifier                               ...                     True\nLength: 79, dtype: bool, 10: Index(['RtpStateBitfield', 'DefaultBrowsersIdent..., 'Wdft_RegionIdentifier'],\n      dtype='object'), 11: 35, 12: 35, 18: nan, 19: nan, 20: nan, 21: 0          7.0\n1          7.0\n2          7.0\n3  ...RtpStateBitfield, Length: 8921483, dtype: float16, 22: nan, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'VotingClassifier': <class 'sklearn.ensemble.voting_classifier.VotingClassifier'>, 'XGBClassifier': <class 'xgboost.sklearn.XGBClassifier'>, 'X_test':          ProductName  EngineVersion  AppVersion ...              10.0  \n\n[7853253 rows x 78 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\southman\\Documents\\GitHub\\mmp\\source\\<ipython-input-54-054461f0af81> in <module>()\n     21 #    \"rf__n_estimators\":[45], \"rf__max_depth\":[20], \"rf__min_samples_leaf\":[3],\n     22 #    'mlp__solver':['adam'], 'mlp__max_iter':[1000], 'mlp__early_stopping':[True], \n     23 #    'mlp__hidden_layer_sizes':[(128,64,32)],'mlp__activation':['logistic'],\n     24 }\n     25 clf = GridSearchCV(clf_eb, parameters, n_jobs=-1, cv=5)\n---> 26 clf.fit(X_train, y_train)\n     27 #print(clf.best_params_)\n     28 score = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n     29 print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" % (score.mean(), score.std(), \"eb\"))\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=         ProductName  EngineVersion  AppVersion ...              11.0  \n\n[8921483 rows x 78 columns], y=0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =          ProductName  EngineVersion  AppVersion ...              11.0  \n\n[8921483 rows x 78 columns]\n        y = 0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Wed Dec 26 17:29:25 2018\nPID: 6116              Python 3.6.5: C:\\Users\\southman\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = <class 'list'> instance\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = <class 'tuple'> instance\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=<class 'pandas.core.frame.DataFrame'> instance, y=0          0\n1          0\n2          0\n3        ...Name: HasDetections, Length: 8921483, dtype: int8, scorer={'score': <function _passthrough_scorer>}, train=memmap([1783781, 1783782, 1783784, ..., 8921480, 8921481, 8921482]), test=memmap([      0,       1,       2, ..., 1784812, 1784813, 1784814]), verbose=0, parameters={'xgb__colsample_bytree': 0.84, 'xgb__gamma': 0.2, 'xgb__learning_rate': 0.2, 'xgb__max_depth': 4, 'xgb__min_child_weight': 4, 'xgb__reg_alpha': 0.01, 'xgb__subsample': 0.9}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method VotingClassifier.fit of VotingClas...orm=None, n_jobs=1, voting='soft', weights=None)>\n        X_train =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y_train = 1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in fit(self=VotingClassifier(estimators=[('xgb', XGBClassifi...form=None, n_jobs=1, voting='soft', weights=None), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=1783781    1\n1783782    1\n1783784    1\n1783787  ...Name: HasDetections, Length: 7137185, dtype: int8, sample_weight=None)\n    184         transformed_y = self.le_.transform(y)\n    185 \n    186         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n    187                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n    188                                                  sample_weight=sample_weight)\n--> 189                 for clf in clfs if clf is not None)\n        clfs = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),)\n    190 \n    191         return self\n    192 \n    193     @property\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object VotingClassifier.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object VotingClassifier.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_fit_estimator>, (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64)), {'sample_weight': None})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_fit_estimator>\n        args = (XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9),          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], array([1, 1, 1, ..., 1, 1, 0], dtype=int64))\n        kwargs = {'sample_weight': None}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py in _parallel_fit_estimator(estimator=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None)\n     26 def _parallel_fit_estimator(estimator, X, y, sample_weight=None):\n     27     \"\"\"Private function used to fit an estimator within a job.\"\"\"\n     28     if sample_weight is not None:\n     29         estimator.fit(X, y, sample_weight=sample_weight)\n     30     else:\n---> 31         estimator.fit(X, y)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...1, seed=None, silent=True,\n       subsample=0.9)>\n        X =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        y = array([1, 1, 1, ..., 1, 1, 0], dtype=int64)\n     32     return estimator\n     33 \n     34 \n     35 class VotingClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, booster='gbtree', ...=1, seed=None, silent=True,\n       subsample=0.9), X=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], y=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n    688         if sample_weight is not None:\n    689             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    690                                     missing=self.missing, nthread=self.n_jobs)\n    691         else:\n    692             train_dmatrix = DMatrix(X, label=training_labels,\n--> 693                                     missing=self.missing, nthread=self.n_jobs)\n        self.missing = nan\n        self.n_jobs = 1\n    694 \n    695         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    696                               evals=evals,\n    697                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], label=array([1, 1, 1, ..., 1, 1, 0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=None, feature_types=None, nthread=1)\n    358                 self._feature_types = feature_types\n    359             return\n    360 \n    361         data, feature_names, feature_types = _maybe_pandas_data(data,\n    362                                                                 feature_names,\n--> 363                                                                 feature_types)\n        feature_types = None\n    364 \n    365         data, feature_names, feature_types = _maybe_dt_data(data,\n    366                                                             feature_names,\n    367                                                             feature_types)\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in _maybe_pandas_data(data=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns], feature_names=['ProductName', 'EngineVersion', 'AppVersion', 'AvSigVersion', 'IsBeta', 'RtpStateBitfield', 'IsSxsPassiveMode', 'DefaultBrowsersIdentifier', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled', 'HasTpm', 'CountryIdentifier', 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'Platform', 'Processor', 'OsVer', ...], feature_types=['float', 'float', 'float', 'float', 'int', 'float', 'int', 'float', 'float', 'float', 'float', 'int', 'int', 'float', 'float', 'float', 'int', 'float', 'float', 'float', ...])\n    237             feature_names = data.columns.format()\n    238 \n    239     if feature_types is None:\n    240         feature_types = [PANDAS_DTYPE_MAPPER[dtype.name] for dtype in data_dtypes]\n    241 \n--> 242     data = data.values.astype('float')\n        data =          ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns]\n        data.values.astype = undefined\n    243 \n    244     return data, feature_names, feature_types\n    245 \n    246 \n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in values(self=         ProductName          ...            Wdf...                11.0\n\n[7137185 rows x 78 columns])\n   4624         --------\n   4625         pandas.DataFrame.index : Retrievie the index labels\n   4626         pandas.DataFrame.columns : Retrieving the column names\n   4627         \"\"\"\n   4628         self._consolidate_inplace()\n-> 4629         return self._data.as_array(transpose=self._AXIS_REVERSED)\n        self._data.as_array = <bound method BlockManager.as_array of BlockMana...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n        self._AXIS_REVERSED = True\n   4630 \n   4631     @property\n   4632     def _values(self):\n   4633         \"\"\"internal implementation\"\"\"\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in as_array(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32, transpose=True, items=None)\n   3944             mgr = self\n   3945 \n   3946         if self._is_single_block or not self.is_mixed_type:\n   3947             arr = mgr.blocks[0].get_values()\n   3948         else:\n-> 3949             arr = mgr._interleave()\n        arr = undefined\n        mgr._interleave = <bound method BlockManager._interleave of BlockM...ock: slice(55, 56, 1), 1 x 7137185, dtype: int32>\n   3950 \n   3951         return arr.transpose() if transpose else arr\n   3952 \n   3953     def _interleave(self):\n\n...........................................................................\nC:\\Users\\southman\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _interleave(self=BlockManager\nItems: Index(['ProductName', 'Engin...lock: slice(55, 56, 1), 1 x 7137185, dtype: int32)\n   3955         Return ndarray from blocks with specified item order\n   3956         Items must be contained in the blocks\n   3957         \"\"\"\n   3958         dtype = _interleaved_dtype(self.blocks)\n   3959 \n-> 3960         result = np.empty(self.shape, dtype=dtype)\n        result = undefined\n        self.shape = (78, 7137185)\n        dtype = dtype('float64')\n   3961 \n   3962         if result.shape[0] == 0:\n   3963             # Workaround for numpy 1.7 bug:\n   3964             #\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold \n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train,y_train.values)):\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(lgb_params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "submission = pd.concat([ID_test, pred] ,axis=1)\n",
    "submission_pca.to_csv('../result/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
